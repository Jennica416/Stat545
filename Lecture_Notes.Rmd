---
title: "Stat 545 Lecture Notes"
author: "By Jennica Nichols"
date: "September 24, 2017"
output: 
  html_document:
    keep_md: true
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Stat545
These are my personal notes from Stat 545 to help with my.

## Lecture 1 
### Add text to README file
Go to Github and get link to clone. Open using in RStudio and pull to get the latest version. You can then make edits locally, where you then commit changes and then push back to the repository.

## Lecture 2
No notes to add

## Lecture 3
No notes to add

## Lecture 4
### Changing output format
The following YAML formatting at the top for a markdown file will make sure that I keep the md intermediate file.

output:
  html_document:
    keep_md: true  
    
[Here is information on YAML features for Markdown](http://rmarkdown.rstudio.com/html_document_format.html)

[Here is a Markdown Cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)

## Lecture 5

The first part of the lecture is to look at working with a dataframe
```{r}
##number of columns 
ncol(iris)

##column names
colnames(iris)

##number of rows
nrow(iris)

##smallest values for each numeric variable
summary(iris)

##make a histogram of Petal.Width
hist(iris$Petal.Width)
```

The second part of the lecture is to learn the fundamentals of dplyr. The package's primary functions are:

* Pick observations by their values (filter()).
* Pick variables by their names (select()).
* Reorder the rows (arrange()).
* Create new variables with functions of existing variables (mutate()).
* Collapse many values down to a single summary (summarise()).
* Then there’s group_by(), which can be used in conjunction with all of these.

```{r, warning=FALSE}
#load libraries
library(dplyr)
library(gapminder)

#use filer
filter(gapminder, country=="Canada")
```
Relational operators are logical expressions that will give you either a TRUE or FALSE output. 
* a == b means	a is equal to b
* a != b means 	a is not equal to b.
* a > b	means a is greater than b.
* a < b	means a is less than b.
* a >= b	means a is greater than or equal to b.
* a <= b	means a is less than or equal to b.
* a %in% b	means a is an element in b

* a | b means a or b
* a & b means a and b

```{r}
#testing these out
4 %in% c(1, 2, 3, 4, 5)

## Canada entries before 1970
filter(gapminder, country == "Canada", year <1970)

## Canada and Kenya entries after 1985
filter(gapminder, country %in% c("Canada", "Kenya"), year>1985)

## Canada and Kenya entries from the 1960s
filter(gapminder, country %in% c("Canada", "Kenya"), year %in% 1960:1969)

## Select only continent and country rows
select(gapminder, continent, country)
```
Next is testing piping, which is where you chain together functions to run code efficiently. 

```{r}
#Select country, year, and GDP per capita for Canada and Kenya entries in the 1960s
gapminder %>%
  filter(country %in% c("Canada", "Kenya"), year %in%
           1960:1969) %>%
  select(country, year, gdpPercap)

#Take all countries in Europe that have a GPD per capita greater than 10000, and select all variables except gdpPercap
gapminder %>%
  filter(continent=="Europe", gdpPercap>10000) %>%
  select(-gdpPercap)

#Order the data frame by year, then descending by life expectancy. Rearrange data frame so year comes first then life expectancy
gapminder %>%
  arrange(pop, desc(lifeExp)) %>%
  select(year, lifeExp, everything())
```

You can use mutate to create new variables that are calculated from other variables within the data frame. 
```{r}
mutate(gapminder, 
       gdp = gdpPercap * pop, 
       gdpBill = round(gdp/1000000000, 1))
```

Summarize reduces the tibble to summary statistics, which is very useful when used with group_by
```{r}
gapminder %>% 
    group_by(country) %>% 
    summarize(mean_pop=mean(pop), sd_pop=sd(pop))

#Find the minimum GDP per capita experienced by each country
gapminder %>%
  group_by(country) %>%
  summarize(minGDP = min(gdpPercap))

#Find how many years of records does each country have
gapminder %>%
  group_by(country) %>%
  summarize(n_distinct(year))

#Within Asia, what are the min and max life expectancies experienced in each year?
gapminder %>% 
    filter(continent=="Asia") %>% 
    group_by(year) %>% 
    summarize(minexp=min(lifeExp),
              maxexp=max(lifeExp))
```
If want additional introduction to dplyr, 
*[Stats 545 Intro Part 1](http://stat545.com/block009_dplyr-intro.html)
*[Stats 545 Intro Part 2](http://stat545.com/block010_dplyr-end-single-table.html)

## Lecture 6
This lecture is about ggplot2. 

```{r, warning=FALSE}
#load library
library(ggplot2)
library(gapminder)

#create first layer that contains dataset and an indication of what variables will go to what scale
p <- ggplot(gapminder, aes(x=year, y=lifeExp))

#this is blank as you need to layer on points and asthetics which is done using a "+"
p + geom_point(alpha=0.25)

#make a scatterplot of GDP per capita and life expectancy
p2 <- ggplot(gapminder, aes(x=gdpPercap, y=lifeExp))
p2+ geom_point(aes(size=year, color=continent, alpha=1/20))

#log transformation
p3 <- p2 + geom_point() + scale_x_log10()

#Colour log transformation by continent and set transparency and size
p4 <- p3 + geom_point(aes(color = continent), alpha=(1/3), size=3)

#Add a smooth line without standard error and using lm
p4 + geom_smooth(method=lm, se = FALSE)

#Take advantage of facetting (factoring)
p4 + facet_wrap(~continent)

##subsetting: looking at 4 countries
jCountries <- c("Canada", "Kenya", "France", "India")

ggplot(subset(gapminder, country %in% jCountries),
       aes(x = year, y = lifeExp, color= country)) + geom_line() +   geom_point()

#Make a plot of year (x) vs lifeExp (y), with points coloured by continent. Then, fit a regression line to each continent, without the error bars. If you can, try piping the data frame into the ggplot function
q <- ggplot(gapminder, aes(x=year, y=lifeExp, color=continent))

q + geom_point()+ geom_smooth(method=lm, se = FALSE)

##Make a plot of year (x) vs lifeExp (y), facetted by continent. Then, fit a smoother through the data for each continent, without the error bars. Choose a span that you feel is appropriate.
q + geom_point()+ geom_smooth(method=lm, se = FALSE) + facet_wrap(~continent)

##Plot the population over time (year) using lines, so that each country has its own line. Add alpha transparency to your liking.Add points to the plot in Exercise 7.
r <- ggplot(gapminder, aes(x=year, y=pop, group=country))
r + geom_line(alpha=1/3) 

r2 <-r + geom_line(alpha=1/3)
r2 + geom_point() 
```

##  Lecture 7
```{r}
# Regression curves
# Regression analysis fits some curve through the data, representing the mean of Y given the specified X value. Sometimes you assume a line (linear model) or can apply a general curve (i.e. a smoother)

vc1 <- ggplot(gapminder, aes(year, lifeExp)) +
    geom_point() 
vc1 + geom_smooth(se=FALSE)

# Exercise 1: Make a plot of year (x) vs lifeExp (y), with points coloured by continent. Then, to that same plot, fit a straight regression line to each continent, without the error bars. If you can, try piping the data frame into the ggplot function

ggplot(gapminder, aes(year, lifeExp, colour=continent)) +
  geom_point() +  # need this to show points on graph
  geom_smooth(method= "lm", se=FALSE)

# Facetting separates data from each group into its own “mini plot”, called a panel. These panels are arranged next to each otherfor easier comparison. There are two facetting functions in ggplot2: (1) facet_wrap: 1D facetting and (2) facet_grid: 2D facetting. Example of (1):

ggplot(gapminder, aes(gdpPercap, lifeExp)) +
    facet_wrap(~ continent) +
    geom_point()

# Exercise 2: Make a plot of year (x) vs lifeExp (y), facetted by continent. Then, fit a smoother through the data for each continent, without the error bars. Choose a span that you feel is appropriate. NOTE: A small span results in a more jagged curve; a larger one results in a smoother curve. You have to find one that fits your data

ggplot(gapminder, aes(year, lifeExp)) +
  geom_point() +
  facet_wrap(~continent)+
  geom_smooth(method = "lm", se=FALSE, span=1)

# Facet_grid allows you to add a third variable so each row corresponds to one grouping and each column corresponds to another grouping. facet_grid(var 1~ var 2) Example 3: Look at continent and population size by “small” (<=7,000,000 population) and “large” (>7,000,000 population) countries. 

vc2 <- gapminder %>% 
    mutate(size=ifelse(pop > 7000000, "large", "small")) %>%     ggplot(aes(gdpPercap, lifeExp)) +
    facet_grid(size ~ continent) 

vc2 + geom_point(aes(colour=year))

# Connect the dots with geom_line (connect dots left-to-right) or geom_path (conects dots in the order they appear within the data frame). With these geoms, you must specify group=VARIABLE in your aesthetics (aes function), otherwise ggplot won’t distinguish between groups. Example:
ggplot(gapminder, aes(year, lifeExp, group=country)) +
    geom_line(alpha=0.2)

# geom_path is typically used when a “time” variable is not shown on an axis. For example, let’s look at a scatterplot of pop vs. gdpPercap of Afghanistan, and let’s “connect the dots” in the order of time. Example:

gapminder %>%
    filter(country=="Afghanistan") %>% 
    arrange(year) %>% 
    ggplot(aes(pop, gdpPercap)) +
    geom_point() +
    geom_path()

# Example 4:  Plot the population over time (year) using lines, so that each country has its own line. Colour by  gdpPercap. Add alpha transparency to your liking. Fit it to a log 10 scale.

##remember group is essential for this!

ggplot(gapminder, aes(year, pop, group=country)) + 
  geom_line(aes(colour=gdpPercap), alpha=0.2) +
  geom_point() +
  scale_y_log10()
 
```

## Lecture 8
### Modeling
First we will look at linear regression using the **lm()** function.
```{r}
# create a linear model
fit1 <- lm(lifeExp ~ log(gdpPercap), data=gapminder)
fit1

# can make predictions using the model. Remember if you don’t specify new data, it will make predictions using the existing X values.
predict(fit1) %>% head

# can plot again the original x values
qplot(log(gapminder$gdpPercap), predict(fit1))
 
# can predict with new data as long as the data frame has the same column names as the x values.
(my_newdata <- data.frame(gdpPercap=c(100, 547, 289)))

predict(fit1, newdata=my_newdata)

predict(fit1, newdata=filter(gapminder, country=="Canada"))

# can extract model characteristics
  #model coefficients
  coef(fit1)
  
  #residuals (looking at the first 6 and then plotting all)
  resid(fit1) %>% head
  
  qplot(log(gapminder$gdpPercap), resid(fit1)) +
    geom_hline(yintercept=0, linetype="dashed", colour="red")

  #lots of information can be determined using summary, such as p-values and standard errors
  summary(fit1)
  
  #can extract specifics from the summary
  sum1 <- summary(fit1)
  
    #r-squared and r-square adjusted
    sum1$r.square
    sum1$adj.r.squared
    
    #estimated standard deviation of the random error term
    sum1$sigma
    
```

#### Other Models:
1.  generalized linear models (such as logistic regression). For this, you use the **glm()** function. It is quite similar to lm, except you need to specify what model to run using the family argument. Syntax includes:

    * Poisson regression:
glm(y ~ x1 + x2 + ... + xp, family=poisson, data=your_data_frame)

    * Logistic (aka Binomial) regression:
glm(y ~ x1 + x2 + ... + xp, family=binomial, data=your_data_frame)

2. Generalized) Mixed Effects Models:
Two R packages are available: lme4 and nlme.
Check out [this](https://stats.stackexchange.com/questions/5344/how-to-choose-nlme-or-lme4-r-library-for-mixed-effects-models) discussion for a comparison of the two packages.

3. Kernel smoothing (i.e. fitting a “smoother”):
Check out the loess function.

4. Generalized Additive Models:
The gam function in either the gam package or mgcv package.

5. Robust linear regression: 
The rlm function in the MASS package is your friend

### More dplyr
One of the most powerful functions is using **mutate()** with grouped tibble. 
```{r}
# Exercise 1: Calculate the growth in population since the first year on record for each country
gapminder %>%
  group_by(country) %>%
  mutate(pop_growth = pop-pop[1])

# What about growth compared to 1972?
gapminder %>%
  group_by(country) %>%
  mutate(pop_growth = pop-pop[year==1972])

```

* Vectorized Functions: These take a vector, and operate on each component independently to return a vector of the same length. In other words, they work element-wise.
    * Examples are cos, sin, log, exp, round.
    * We don’t need to group_by in order to mutate with these.

*Aggregate Functions: These take a vector, and return a vector of length 1 – as if “aggregating” the values in the vector into a single value.
    * Examples are mean, sd, length, typeof.
    * We use these in dplyr’s summarise function.

* Window Functions: these take a vector, and return a vector of the same length that depends on other values in the vector.
    * Examples are lag, rank, cumsum.
    * See the window-functions vignette for the dplyr package.

### More ggplot
* The [ggplot2 cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf) is very helpful for data visualization. 

1. Themes
You can change the look of the plot (e.g. font, justification of title, line thickness) using existing themes. There are complete themes already created, which you can see [here](http://ggplot2.tidyverse.org/reference/ggtheme.html). 
```{r}
# An example of using the theme_bw theme
p1 <- ggplot(gapminder, aes(gdpPercap, lifeExp)) +
    facet_wrap(~ continent) +
    geom_point(colour="#386CB0", alpha=0.2) +
    scale_x_log10()
p1 + theme_bw()
```
You can modify theme elements by selecting an argument  name (e.g. axis.title, strip.text) and then specifying the value using one of these functions:
* element_blank: leave things as is
* element_rect: change features of a rectangle
* element_line: change features of a line
* element_text: change fonts

```{r}
# For example, change the strip background to orange as well as increase font size to 14 and bold panel titles
p1 +
  theme_bw() +  # before modifications or overrides changes
    theme(strip.background = element_rect(fill="orange"),
          axis.title = element_text(size=14),
          strip.text = element_text(size=14, face="bold"))
```
2. Modifying scales
Scales control the mapping from data to aesthetics. They take your data and turn it into something that you can see, like size, colour, position or shape. Scales also provide the tools that let you read the plot: the axes and legends. Formally, each scale is a function from a region in data space (the domain of the scale) to a region in aesthetic space (the range of the scale). Go [here](https://github.com/hadley/ggplot2-book/blob/master/scales.rmd) for a lesson.

We can modify scales using a suite of functions that have the following naming convention: scale_a_b, where:
* a is the scale you want to change (e.g. colour, size).
* b typically speaks to the nature of the variable (e.g. continuous, discrete, log10).
* Examples: scale_x_continuous, scale_colour_discrete, scale_y_sqrt.
* These are added as layers

**Useful Arguments**
1. name: The first argument. Indicate the name of the scale/legend here. Can also use labs().
```{r}
# Examples
p1 + scale_y_continuous("Life Expectancy")
p1 + labs(x="GDP per capita", 
          y="Life Expectancy",
          title="My Plot")

ggplot(gapminder, aes(gdpPercap, lifeExp)) +
    geom_point(aes(colour=continent),
               alpha=0.2) +
    scale_colour_discrete("Continents of\n the World")
```

2. breaks: you get to specify where along the scale you'd like to display a value for continuous data. Numbers are on the scale of the data (such as population).
```{r}
# Example
## Log lines:
p1 + scale_x_log10(breaks=c((1:10)*1000,
                            (1:10)*10000))

p2 <- ggplot(gapminder, aes(gdpPercap, lifeExp)) +
    geom_point(aes(colour=pop/10^9),
               alpha=0.2)

## Default breaks
p2 + scale_colour_continuous("Population\nin billions")

## New breaks
p2 + scale_colour_continuous("Population\nin billions",
                             breaks=seq(0,2,by=0.2))
```
  
3. Labels
Text to replace the data value labels. Most useful for discrete data.
```{r}
# Example
ggplot(gapminder, aes(gdpPercap, lifeExp)) +
    geom_point(aes(colour=continent), alpha=0.2) +
    scale_colour_discrete(labels=c("Af", "Am", "As", "Eu", "Oc"))
```
  
4. Limits
Lower and upper bounds of the data that you'd like displayed. Leave one as NA if you want to use the default.
```{r}
p1 + scale_y_continuous(limits=c(60,NA))
```
  
5. Position
Position of the scale. Also controllable using theme for the legend.
```{r}
p1 + scale_y_continuous(position="right")
p2 + theme(legend.position = "bottom")
```

### Exercises
Practice what was learned above. 

1. Suppose we want to calculate some quantity for each country in the gapminder data set. For each of the following quantities, indicate whether the function is vectorized, aggregate, or window, and use dplyr functions to calculate the specified variable.
    a) The change in population from 1962 to 1972.
    
```{r}
## aggregrate
gapminder %>%
  group_by(country) %>%
  summarize(pop_change = pop[year==1972]-pop[year==1962])
```

    b) Population in Billions
```{r}
## vectorize
gapminder %>%
  group_by(country) %>%
  mutate(pop_billion = pop/10^9)
```

    c) Lagged gdpPercap
```{r}
## window
gapminder %>% 
    group_by(country) %>% 
    arrange(year) %>% 
    mutate(lag_gdpPercap=lag(gdpPercap)) %>% 
    filter(!is.na(lag_gdpPercap))
```

2. For the gapminder dataset, make a spaghetti plot showing the population trend (in millions) over time for each country, facetted by continent. Make as many of the following modifications as you can:

*Colour each line by the log maximum gdpPercap experienced by the country.
*Rotate the x-axis labels to be vertical.
*Remove the x-axis title.
*Give the legend an appropriate title.
*Put the y-axis on a log-scale.
*Rename the y-axis title.
*Add more numbers along the y-axis.
*Give the plot a title, and center the title.
*Only label the x axis with years 1950, 1975, and 2000.
*Move the colour scale to the bottom.
*Rename the colour legend

```{r}
gapminder %>%
  group_by(country) %>%
  mutate(pop_mill = pop/10^6, max_gdpPercap = max(gdpPercap)) %>%
  ggplot(aes(year, pop_mill)) +
    facet_wrap(~ continent) +
    geom_line(aes(group=country, colour=log(max_gdpPercap)), alpha=0.6) +
  theme_bw() +
  labs(title="Population Trends by Country over Time") +
  scale_y_log10( "Population (millions)",
                 breaks=c(0.1, 1, 10, 100, 1000),
                labels=c(0.1, 1, 10, 100, 1000)) +
  scale_x_continuous("", breaks=c(1950, 1975, 2000)) +
  scale_colour_continuous("log Max\nGDP per capita") +
  theme(axis.text.x = element_text(angle=90),
          plot.title = element_text(hjust=0.5),
          legend.position = "bottom")
                 
```

## Lecture 9
It’s rare that a data analysis involves only a single table of data. In practice, you’ll normally have many tables that contribute to an analysis, and you need flexible tools to combine them. In dplyr, there are three families of verbs that work with two tables at a time (see below). All work similarly: the first two arguments are x and y, and provide the tables to combine. The output is always a new table with the same type as x.

1. **Mutating Joins**, which add new variables to one table from matching rows in another.
```{r warning=FALSE, message=FALSE}
#load library
library("nycflights13") 
  #data saved as seveeral data sets automatically: flights, airlines, planes, weather 

##Basic Join:
# Drop unimportant variables so it's easier to understand the join results.
flights2 <- flights %>% select(year:day, hour, origin, dest, tailnum, carrier)

#join by carrier
flights2 %>% 
  left_join(airlines)

```
Each mutating join takes an argument **by** that controls which variables are used to match observations in the two tables. There are a few ways to specify it:
* by=NULL, dplyr will will use all variables that appear in both tables, a natural join.
```{r}
# the flights and weather tables match on their common variables: year, month, day, hour and origin
flights2 %>% left_join(weather)
```

* by="x", join is controlled by a character vector
```{r}
# flights and planes have year columns, but they mean different things so we only want to join by tailnum. 
flights2 %>% left_join(planes, by = "tailnum")
```

* by = c("x" = "a"), join is controlled by a named character vector. This will match variable *x* in table x to variable *a* in table a. The variables from use will be used in the output.
```{r}
# Each flight has an origin and destination airport, so we need to specify which one we want to join to
flights2 %>% left_join(airports, c("dest" = "faa"))

flights2 %>% left_join(airports, c("origin" = "faa"))
```
### Types of Mutating Joins
```{r}
#create two test data frames to illustrate types
(df1 <- data_frame(x = c(1, 2), y = 2:1))
(df2 <- data_frame(x = c(1, 3), a = 10, b = "a"))
```
a) **inner_join(x,y)** only includes observations that match in both x and y.
```{r}
# joining, by = "x"
df1 %>% inner_join(df2)
```

b) **left_join(x,y)** includes all observations in *x*, regardless of whether they match or not. This is the most commonly used join because it ensures that you don’t lose observations from your primary table.
```{r}
# joining, by = "x"
df1 %>% left_join(df2)
```
c) **right_join(x, y)** includes all observations in y. It’s equivalent to left_join(y, x), but the columns will be ordered differently.
```{r}
df1 %>% right_join(df2)
```
d) **full_join()** includes all observations from x and y.
```{r}
df1 %>% full_join(df2)
```
**NOTE:**The left, right and full joins are collectively know as **outer joins**. When a row doesn’t match in an outer join, the new variables are filled in with missing values.

  
2. **Filtering joins**, which filter observations from one table based on whether or not they match an observation in the other table. Filtering joins match obserations in the same way as mutating joins, but affect the observations, not the variables. There are two types:
a) **semi_join(x, y)** keeps all observations in x that have a match in y.
b) **anti_join(x, y)** drops all observations in x that have a match in y

These are most useful for diagnosing join mismatches:
```{r}
# there are many flights in the nycflights13 dataset that don’t have a matching tail number in the planes table
flights %>% 
  anti_join(planes, by = "tailnum") %>% 
  count(tailnum, sort = TRUE)
```
  
3. **Set operations** combine the observations in the data sets as if they were set elements. These expect the x and y inputs to have the same variables, and treat the observations like sets:
    * **intersect(x, y)**: return only observations in both x and y
    * **union(x, y)**: return unique observations in x and y
    * **setdiff(x, y)**: return observations in x, but not in y.
```{r}
#create two simple datasets to test
(df1 <- data_frame(x = 1:2, y = c(1L, 1L)))
(df2 <- data_frame(x = 1:2, y = 1:2))

#only keeps one observation 
intersect(df1, df2)

#has three observations (1 shared between two data sets, 1 unique observation from df1, 1 unique observation fom df2)
union(df1, df2)

#only 1 observation (1 unique from df1)
setdiff(df1, df2)

#only 1 observation (1 unique from df2)
setdiff(df2, df1)

```

### Coercion Rules
When joining tables, dplyr is a little more conservative than base R about the types of variable that it considers equivalent. This is mostly likely to surprise if you’re working factors:
    * Factors with different levels are coerced to character
    * Factors with the same levels in a different order are coerced to character
    * Factors are preserved only if the levels match exactly
    * Factor and a character are coerced to character

## Exercises:
```{r}
#Consider the following areas of countries, in hectares:
(areas <- data.frame(country=c("Canada", "United States", "India", "Vatican City"), area=c(998.5*10^6, 983.4*10^6, 328.7*10^6, 44)) %>% 
     as.tbl)
```

1) To the gapminder dataset, add an area variable using the areas tibble. Be sure to preserve all the rows of the original gapminder dataset.
```{r}
left_join(gapminder, areas)
```
  
2) To the gapminder dataset, add an area variable using the areas tibble, but only keeping obervations for which areas are available
```{r}
inner_join(gapminder, areas)
```
  
3) Use a _join function to output the rows in areas corresponding to countries that are not found in the  gapminder dataset.
```{r}
anti_join(areas, gapminder)
```
  
4) Use a _join function to output the rows in areas corresponding to countries that are found in the  gapminder dataset.
```{r}
semi_join(areas, gapminder, by="country")
```
  
5) Construct a tibble that joins gapminder and areas, so that all rows found in each original tibble are also found in the final tibble.
```{r}
full_join(areas, gapminder, by="country")
```
  
6) Subset the gapminder dataset to have countries that are only found in the areas data frame.
```{r}
semi_join(gapminder, areas)
```
  
7) Subset the gapminder dataset to have countries that are not found in the areas data frame.
```{r}
anti_join(gapminder, areas)
```
**NOTE:** A [helpful cheatsheet](http://stat545.com/bit001_dplyr-cheatsheet.html) has been created for dplyr join functions.

## Lecture 10
Always want to make sure your data is tidy (i.e. each column is a variable and each row is an observation).
```{r}
#subgroup countries from the Americas
Americas <- 
  gapminder %>%
  group_by(country) %>%
  filter(continent == "Americas", year == 2007)

#plot life Expectancy of countries in the Americans in 2007

p <- ggplot(Americas, aes(x= country, y = lifeExp, fill = lifeExp))
p + geom_bar(stat = "identity") +
  scale_fill_gradient(low = "red",high="red4" ) +
  guides(fill = guide_legend(reverse=TRUE))+
  theme(axis.text.x = element_text(angle = 90, hjust=1))+
  labs(title = "Life Expectancy of Countries in the Americans in 2007")
```
Most data that you get will be untidy because (1) people don't know the tidy principles and (2) data is often organied to facilitate some use other than analysis (e.g. easier data entry).

To tidy your data:
1) Figure out what the variables and observations are
2) Resolve any common issues (e.g. one variable is spread across multiple columns, one observation is scattered across multiple rows)

Common functions do this include(from **tidyr package**):

### Gathering
```{r}
# Using data from base package
table4a
table4b

# Making it tidy
(tidy4a <-
  table4a %>% 
    gather(`1999`, `2000`, key = "Year", value = "cases"))

## Note that “1999” and “2000” are non-syntactic names (because they don’t start with a letter) so we have to surround them in backticks

(tidy4b <-
  table4b %>%
  gather(`1999`, `2000`, key = "Year", value = "Population"))

## Combining together to create one data frame
left_join(tidy4a, tidy4b)
```
  
### Spreading
Spreading is the opposite of gathering. You use it when an observation is scattered across multiple rows. The following table has countries as the observation, but they are spread across two rows:
```{r}
## Using data from base
table2

## Tidy it
table2 %>%
  spread(key = type, value = count)
```
  
## Separate
Separate pulls apart one column into multiple by splitting wherever a seperator character appears.
* By default, the function will split values wherever it sees a non-alphanumeric character (i.e. a character that isn’t a number or letter). For example, below, separate() split the values of rate at the forward slash characters. If you wish to use a specific character to separate a column, you can pass the character to the sep argument.
* The function will by default make the split columns into characters. Can add conver = TRUE to ask the function to try to do better
```{r}
# Using data from base
table3

# Tidy data. Rate contains cases and population
table3  %>%
  separate(rate, into = c("Cases", "Population"))

# Tidy data. Rate contains cases and population (Take 2)
table3  %>%
  separate(rate, into = c("Cases", "Population"), convert = TRUE)
```
  
You can also pass a vector of integers to sep that will  interpret the integers as positions to split at. Positive values start at 1 on the far-left of the strings; negative value start at -1 on the far-right of the strings. When using integers to separate strings, the length of *sep* should be one less than the number of names in *into*. For example, you may want to only have two digits for year:
```{r}
table3 %>% 
  separate(year, into = c("century", "year"), sep = 2) %>%
  select(-century)

```


# Lecture 11
```{r}
#install data set and libraries
devtools::install_github("JoeyBernhardt/singer")
library(singer)
library(tidyverse)
library(reshape2)

# Task 1
## move from wide format to narrow
data("singer_locations")

hfd_y <-singer_locations %>%
  select(year, duration:artist_familiarity) %>%
  gather(key= "Measures", value = "My_Values", 
    duration:artist_familiarity)

## graph the above in a meaningful way
hfd_y %>%
  filter(year > 1950) %>%
  ggplot(aes(x = year, y = My_Values)) +
  geom_point() +
  facet_wrap(~Measures, scales = "free_y")  #free_y = allows y scales to match data for each graph in facet

# Task 2: Add unique identifer and move back to wide format
hfd_y2 <-singer_locations %>%
  select(song_id, year, duration:artist_familiarity) %>%
  gather(key= "Measures", value = "My_Values", 
    duration:artist_familiarity)

hfd_y2 %>%
  spread(Measures, My_Values) #spread only works when each row has it's own unique ID

# Task 3: Use Reshape 2 when do not have a unique ID or when you want to aggregate some rows
hfd_y %>%
  dcast(year ~ Measures, value.var = "My_Values", fun.aggregate = mean, na.rm = TRUE) 

# The above means take the year value, use measures to spread the remaining columns, and use mean to aggregrate all rows for that year
# If used variance instead of mean, you get some rows as N/A because there is only 1 row for that year (and therefore there is no variance to aggreate all the rows for that year)
```
  
The rest of the lecture was about R objectives along with classes different objects apply (an object can belong to more than one class, e.g. ggplot, tibble). Interesting: >%> is a function (class(`%>%`)) and therefore can be used as a function. 

# Lecture 12

Looking at types of objects in R (class() tells you how R sees the object while typeof() shows how it is stored in memory)
```{r}
#load librarys
library(gapminder)
library(tidyverse)
library(singer)

#characters
typeof("X")

#logical
typeof(TRUE)

#list
typeof(gapminder)
 
#function
typeof(lm)
class(lm)

#plot
my_plot <- singer_locations %>%
  ggplot(aes(x = year, y = duration))

typeof(my_plot)
class(my_plot)

#matrix
my_mat <- matrix(c(1:4), nrow = 2, byrow = TRUE)
my_mat

#Change one entry of singer_locations 
singer_locations$year[4] <- as.character(singer_locations$year[4])
  # when you change one entry, the entire column changes
```

## reading a file into R
1. read_csv() is a function in tidyverse that is better than the function in base as it is quicker and it better attempts to guess the right class of the columns

2. read_excel() is a function in the "readxl" package that reads excel files into R files
